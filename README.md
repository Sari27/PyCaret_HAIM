# 1. Introduction

This repository illustrates several functionalities of the PyCaret Classification module. These functionalities have been explored using the data from the [HAIM study](https://www.nature.com/articles/s41746-022-00689-4).

## 2. Data

The data used was the embeddings csv file generated by the HAIM study (*cxr_ic_fusion_1103.csv*). It is available on [Physionet](https://physionet.org/).

## 3. How to use the package

The package consists of two parts:

- The "explore_pycaret_library" folder explores the functionalities of the PyCaret classification module, with one folder dedicated to tests on the setup() function and another folder for other functionalities.
- The "reproduce_HAIM_experiments" folder aims to achieve the best possible results for three of the HAIM experiments: Fracture, Edema and Cardiomegaly. All the experiments have been conducted as closely as possible to the HAIM study, following these steps:
  - Splitting the data into training and testing sets with an 80% - 20% ratio.
  - Using 5-fold cross-validation.
  - Stratifying by patient to avoid data leakage.
  - Stratifying by pathology to balance the target ratio.
  - Conducting an XGBoost-based modeling experiment.
  - The XGBoost tuning process selected the maximum depth of the trees (5â€“8), the number of estimators (200 or 300), and the learning rate (0.05, 0.1, 0.3) based on the parameter value combination that achieved the highest observed AUROC within the training loop.

You can either review the output cells of the Jupyter notebooks or run your own experiments by downloading the embeddings csv file on the *data/* folder.

## 4. Results

For the "explore_pycaret_library" folder: In general, none of the different setup configurations had an impact on the results. Some tested attributes didn't run due to the large amount of data to manipulate. This was the case for "polynomial_features" and "polynomial_degree". As for the "transformation" attribute, the default method 'yeo_johnson' didn't run on the dataset, but when set to the other available method 'quantile', the code ran successfully.

For the "reproduce_HAIM_experiments" folder: For both experiments, we were very close to the study results, but we never surpassed them. The results of the Fracture experiment are not stable due to the small amount of data compared to the other experiments (557 rows compared to over 17,000 rows for the Edema experiment).

## Project Tree

|--- data                                   <- Directory where you should place your embeddings CSV file
|
|--- explore_pycaret_library 
|     |
|     |--- classification_functionalities   <- Directory for exploring PyCaret classification functions
|     |     |--- classification.ipynb       <- Notebook exploring PyCaret classification functions
|     |
|     |--- classification_setup             <- Directory for exploring PyCaret setup attributes
|           |--- notebooks                  <- Directory containing one notebook per attribute test
|
|--- reproduce_HAIM_experiments             <- Directory for reproducing the HAIM experiments
|     |--- Edema.ipynb                      <- Notebook for predicting Edema chest pathology
|     |--- Fracture.ipynb                   <- Notebook for predicting Fracture chest pathology
|     |--- Cardiomegaly.ipynb               <- Notebook for predicting Cardiomegaly chest pathology
